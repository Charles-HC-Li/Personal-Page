<!DOCTYPE html>
<html lang="en">

<head>
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7X87BH2D0S"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-7X87BH2D0S');
</script>
    
    <meta charset="UTF-8">
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, minimum-scale=0.5, maximum-scale=2.0, user-scalable=yes">
    <link rel="stylesheet" type="text/css" href="assets/style.css">
    <title>Haichang Li ÊùéÊµ∑ÁïÖ</title>
</head>

<body>
    <nav class="navbar">
        <div class="left-section">
            <strong>Haichang Li ÊùéÊµ∑ÁïÖ</strong>
        </div>
        <div class="right-section">
            <ul>
                <li><a href="#about">about</a></li>
                <li class="slash">/</li>
                <li><a href="#past">past</a></li>
                <li class="slash">/</li>
                <li><a href="thoughts.html">thoughts</a></li>
                <li class="slash">/</li>
                <li><a href="misc.html">misc</a></li>
                <li class="slash">/</li>
                <li><a href="materials/Haichang Li-Resume.pdf">cv</a></li>
            </ul>
        </div>
    </nav>

    <main>

        <!-- You can add more sections for other content as needed -->
        <div class="img"><img class="img_responsive" src="images/hc.jpg" alt="ProfilePhoto"></div>
        <div styclass="info">
            <p>
            </p><br>
            <h1>Haichang Li</h1>
            <p>
            </p>
            <div>Junior Student</div>
            <div>Purdue University</div>
            <div>Human-AI Collaboration</div>
            <div>Observer Thinker Designer</div>
            <p>
            </p>

            <div>Information | Communication</div>
            <div>Expected Class of 2025</div>
            <div>Purdue University</div>
            <div>Email:&nbsp; li4650 [at] purdue (dot) edu</div>
            <p>
                <span><a href="https://www.linkedin.com/in/haichang-li/">LinkedIn</a></span> /
                <span><a href="https://twitter.com/haichang_li">Twitter</a></span> /
                <span><a href="https://github.com/Charles-HC-Li?tab=repositories">Github</a></span>
            </p>
            <p>
            </p>
        </div>
        <div class="clear"></div>

        <div id="about">
            <h2>HelloWorld&#9997;</h2>

            <p> I am Haichang(Charles) Li(ÊùéÊµ∑ÁïÖ), currently a junior Undergraduate student at <a
                    href="https://www.purdue.edu/">Purdue University</a> studying <a
                    href="https://polytechnic.purdue.edu/degrees/computer-and-information-technology">Information</a>
                and <a href="https://www.cla.purdue.edu/communication/">Communication</a>.
                Before coming to Purdue University, I dropped out of the <a
                    href="https://www.liverpool.ac.uk/courses/xjtlu/electrical-engineering-beng/electrical-and-electronic-engineering-with-a-year-abroad-beng-hons">EEE</a>
                joint program of <a
                    href="https://www.xjtlu.edu.cn/en/study/departments/school-of-advanced-technology/electrical-and-electronic-engineering">XJTLU</a>
                and <a href="https://www.liverpool.ac.uk/electrical-engineering-and-electronics/">UoL</a> for personal
                planning with the grade of the first class honor.</p>
            <p> At Purdue, I was mainly advised by Professors <a href="https://yhlu.net/index.html">Yung-Hsiang Lu</a> and Professor <a href="http://www.lianghe.me/">Liang He</a>, but I was also co-supervised by Professor <a
                                href="https://www.cla.purdue.edu/directory/profiles/yeon-ji-kristen-yun.html">Yeon-Ji
                                Yun</a> in the Department of Music and worked closely with Professor <a href="https://fenglong-ma.github.io/">Fenglong Ma</a> at PSU about NLP(in chronological order). My interests are interdisciplinary and these professors' fields do not overlap, and I am grateful for the privilege of receiving guidance and advice from different directions to grow during my undergraduate years.</p>
            <p>I am currently interested in <b>Human-AI Collaboration</b>, specifically at the intersection of <b>AGI</b> and <b>HCI</b> <i>(in especial creative works like Music & modeling)</i>. My ideal role is to be the link and bridge between <b>external observers</b> and
            <b>designers</b> in this process. I hope to explore how AI can better help human beings to achieve benign
            coexistence, such as in the fields of multi-modal <b>a11y</b>, that is, to help people who
            need help more first and to explore the impact of AI on the world. If you are also
            interested, feel free to drop an email to me&#x1F600;</p>
        </div>

        <h2>News&#127754;</h2>
        <div class="news-container">
            <div class="news-item">
                <p style="color: red;">This website has been temporarily stopped updating from 2023.10! I have stopped looking for opportunities for research intern and am currently working on the multi-agent LLM 4 Fab&Medical projects, which will be updated after February 2024. Thank you for your visit, and welcome peers to email me to discuss and get my latest update!:) </p>
                <p><b>[2023.11]</b> The final version of <a href="https://www.shineresume.com/index">"Shine Resume"</a> is released in Chinese! Hope this will help some of the "hidden" crowd and shine with them! Thanks for the efforts of all the partners this summer. This is the first time for me to complete a commercial project from 0 to 1, from design to implementation and promotion.üé®</p>
            </div>
            <div class="news-item">
                <p><b>[2023.10]</b> I am currently fascinated by <a
                        href="materials/p-socialbot.pdf">using LLM and emotional computing
                        to help people with psychological needs</a>, plz feel free to check out our proposal and leave any comments if you are also
                    interested.ü§ñ</p>
            </div>
            <div class="news-item">
                <p><b>[2023.9]</b> <a href="https://ai4musicians.org/visualize.html">"Visual Music for the Hearing
                        Impaired through synaesthesia"</a> enters the user study phase! Ideally, the paper will be completed by December and Coming soon!üéº</p>
            </div>
        </div>

        <div id="past">
            <h2>Past&#127919;</h2>
            <div class="custom-experience-container">
                <div class="custom-image">
                    <img src="past/socialbot/process.jpg" alt="Experience Image">
                </div>
                <div class="custom-content">
                    <h3>Social Robot for the Depressed and Lonely</h3>
                    <small><em><b>[Project]</b>Project for Assistive Tech with Taehyeon Kim, instructed By Prof. <a
                                href="https://web.ics.purdue.edu/~minb/">Byung-Cheol Min</a></em></small>
                    <p style="font-size: smaller; text-align:justify;">To help people with special needs, such as those
                        with depression or the elderly who are alone, cope with mental health challenges, we propose an
                        innovative approach that uses multimodal social robots, combined
                        with sentiment analysis and natural language interaction technologies. </p>
                        <p style="font-size: smaller; text-align:justify;">The reason for using
                        multimodality is to improve accessibility and accuracy, with multimodal data verifying each
                        other, while also taking into account that some people may not be able to output through a
                        certain mode (such as situations with limited facial expressions, typing difficulties, or
                        inability to speak). The application of sentiment analysis, which helps us understand users'
                        emotions, and LLM, which provide a more human conversational experience through natural language
                        processing, play a key role in this approach. Through this integrated, multimodal approach, our
                        social robots are able to more fully understand and support the mental health needs of our
                        target population, contributing to their emotional well-being.</p>
                    <small><a href="materials/p-socialbot.pdf">PROPOSAL</a> / <a
                            href="https://charles-hc-li.github.io/SocialRobot/index.html">WEB</a> / <a href="https://github.com/Charles-HC-Li/socialbot/tree/main">CODE</a> / PDF</small>
                </div>
            </div>

            <div class="custom-experience-container">
                <div class="custom-image">
                    <img src="past/shineresume/pre.jpg" alt="Experience Image">
                </div>
                <div class="custom-content">
                    <h3>ShineResume: Multimodal AIGC platform for confused graduates</h3>
                    <small><em>An "from 0 to 1" entrepreneurial project@Tanyu obtaining <b>10+ million</b> CNY funding
                            support</em></small>
                    <p style="font-size: smaller; text-align:justify;"> The Post-COVID-19 era has brought a cold winter
                        to the Chinese job market, with companies announcing layoffs and hiring freezes. In such an
                        environment, there exists a group of underserved individuals who come from ordinary schools, and
                        during their college years, they simply follow the prescribed curriculum. They don't know what
                        they're passionate about, what kind of work suits them, or how to start their job search. They
                        find themselves trapped in a cocoon of information gap. </p>
                    <p style="font-size: smaller; text-align:justify;">We aim to have AI collaborate with these
                        individuals, putting people at the center, leveraging multimodal AIGC and LLM. With just the
                        user's background information, we can recommend various industries and positions, extract key
                        terms, and then create and optimize their resumes as per requirements. Additionally, we can
                        perform style transfer for their official photos to meet the desired appearance.</p>
                    <p style="font-size: smaller; text-align:justify;">Our purpose is to let AI be valueable for
                        underserved people, bring benefits to humanity, and help neglected people have the opportunity
                        to find themselves and shine.</p>
                    <small><a href="https://www.shineresume.com/">WEB</a><i>(EC: The fifth avatar in the "WHO ARE WE" column is me, which was designed by the first UI we recruited)</i> </small>
                </div>
            </div>


            <div class="custom-experience-container">
                <div class="custom-image">
                    <img src="past/mus2vid/pre.jpg" alt="Experience Image">
                </div>
                <div class="custom-content">
                    <h3>Synesthesia: Music visualization for the hearing impaired</h3>
                    <small><em><b>[Coming Soon]</b>Supervised By Prof. <a href="https://yhlu.net/index.html">Yung Hsiang Lu</a>
                            and Prof. <a
                                href="https://www.cla.purdue.edu/directory/profiles/yeon-ji-kristen-yun.html">Yeon-Ji
                                Yun</a> </em></small>
                    <p style="font-size: smaller; text-align:justify;">Have you ever thought about synesthesia? There
                        are about 200 million hearing impaired people in the world, and the music we normally enjoy is a
                        luxury for them. For example, when we hear grand piano music, we may conjure up images of
                        medieval battlefields, but those who are equally imaginative and hard of hearing cannot. So, our
                        project is willing to be their ears, based on emotions and AIGC and LLM, we let them use the
                        "see" way to "hear" the music. In the face of the injustices they suffer, our answer takes its
                        own approach, using technology to provide them with a potentially viable approach.</p>
                    <small><a href="https://github.com/Mus2Vid/Mus2Vid-code">CODE</a> / <a
                            href="https://ai4musicians.org/visualize.html">WEB IN CHINESE</a>(IN Chinese) </small>
                </div>
            </div>

            <div class="custom-experience-container">
                <div class="custom-image">
                    <img src="past/thermalhuman/pre.jpg" alt="Experience Image">
                </div>
                <div class="custom-content">
                    <h3>Data driven model for human thermal confort during sports</h3>
                    <small><em>SURF Supervised by Prof. <a
                                href="https://www.xjtlu.edu.cn/en/departments/academic-departments/entrepreneur-college-taicang/staff/long-huang">Long
                                Huang</a></em></small>
                    <p style="font-size: smaller; text-align:justify;">In order to help architects design the interior
                        environment, the interaction between the human body's psychological subjective thermal comfort
                        and the external objective environment is worth studying and observing. Subjective feelings can
                        be reflected through the designed user study, and the PMV model and a variety of data analysis
                        and processing methods can be combined to quantify and predict such psychological feelings, so
                        as to improve the interaction experience between people's psychological feelings and the
                        external physical environment.</p>
                    <small><a href="past/thermalhuman.jpg">POSTER</a></small>
                </div>
            </div>

            <!-- 
        <div class="custom-experience-container">
            <div class="custom-image">
                <img src="past/music2AI.jpg" alt="Experience Image">
            </div>
            <div class="custom-content">
                <h3> </h3>
                <small></small>
                <p style="font-size: smaller; text-align:justify;"></p>
            </div>
        </div>
        -->

            <h2>Contact With Me&#127828;</h2>
            <p>I always enjoy discussing and exchanging ideas with others, welcome to communicate with me.<a
                    href="mailto:li4560@purdue.edu">üì§</a></p>

                <script type='text/javascript' id='clustrmaps'
        src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=a&t=n&d=eSPJmLlY5uirTp0wpmWRSR8oRZhr4IsEBI6Dc-4Jw_Y&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'></script>

    </main>

    <script src="assets/script.js"></script>
    <footer>
        <p style="text-align: center;">&copy; 2023 Haichang Li. The web was inspired by <a
                href="https://www.ziangxiao.com/">Professor Ziang Xiao</a>.</p>
    </footer>
</body>

</html>
